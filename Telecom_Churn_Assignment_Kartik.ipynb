{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telecom Churn Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, ___retaining high profitable customers is the number one business goal___.\n",
    "\n",
    "To reduce customer churn, __telecom companies need to predict which customers are at high risk of churn__.\n",
    "\n",
    "In this project, we will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __Importing Required Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings as w\n",
    "w.filterwarnings('ignore')\n",
    "pd.set_option('max_columns',500)\n",
    "pd.set_option('max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('telecom_churn_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked above, there are 214 numeric columns and 12 non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at data statistics\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In churn prediction, we assume that there are three phases of customer lifecycle :\n",
    "\n",
    "The ‘good’ phase [Month 6 & 7]<br>\n",
    "The ‘action’ phase [Month 8]<br>\n",
    "The ‘churn’ phase [Month 9]<br><br>\n",
    "In this case, since we are working over a four-month window, the first two months are the ‘good’ phase, the third month is the ‘action’ phase, while the fourth month is the ‘churn’ phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for Checking missing values percentages\n",
    "def checkMissingPercent(dataset, cutoff):\n",
    "    missing = round(100*(dataset.isnull().sum()/dataset.shape[0]))\n",
    "    return missing.loc[missing>cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for imputing data \n",
    "def imputeData(df, col_list):\n",
    "    for i in [x + y for y in ['_6','_7','_8','_9'] for x in col_list]:\n",
    "        df[i].fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Handling missing values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since mobile no has all unique values and represents a particular customer, it can be dropped from the dataset.\n",
    "# Similarly, circle_id has all same values(109), it also can be dropped.\n",
    "mod_data.drop(['mobile_number', 'circle_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at missing value ratio in each column\n",
    "checkMissingPercent(mod_data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked above, there are so many columns conatining missing values. Among them, there are some columns which has more than 70% of missing values. We will not directly delete those columns. Let us first check that these values as null because of no transactions or because of some other reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all columns for month of June which has 75% missing values\n",
    "cols = checkMissingPercent(mod_data, 74).index\n",
    "\n",
    "mod_data.loc[mod_data.date_of_last_rech_data_6.isna(),cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked above, all the columns has null values where date of last recharge is missing. This is valid, we can replace these null values with 0 as there is no recharge done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing all the columns other than those containg date with 0 having more than 50% missing value\n",
    "cols = list(filter(lambda x : not x.startswith('date') , checkMissingPercent(mod_data, 50).index))\n",
    "\n",
    "mod_data[cols]=mod_data[cols].apply(lambda x: x.fillna(0))\n",
    "mod_data[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again percent of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkMissingPercent(mod_data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the non-numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=mod_data.select_dtypes(include='object')\n",
    "for i in obj.columns:\n",
    "    print(i,'', obj[i].nunique(),'', obj[i].isna().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already used date to fill the missing values. Further these date columns seems to be irrelevant in our analysis, so we will drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod_data = mod_data.drop(obj.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again checking for the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkMissingPercent(mod_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(checkMissingPercent(mod_data, 0).index)\n",
    "mod_data[cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked above, all the columns have their minimum value 0, but since the missing percent is very low around 4-5%, this can be because of technical or human error, its better to fill these values with median rather than 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filling the columns above with median\n",
    "mod_data[cols]=mod_data[cols].apply(lambda x: x.fillna(x.median()))\n",
    "mod_data[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if our missing value imputation is successfully done or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(mod_data.isna().sum()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates from row\n",
    "mod_data.drop_duplicates(inplace=True)\n",
    "mod_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few columns whose names are not consistent with other columns. Let make them same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(filter(lambda x: x[-1].isalpha(), mod_data.columns)))\n",
    "mod_data.rename(columns={'aug_vbc_3g':'vbc_3g_8', 'jul_vbc_3g':'vbc_3g_7', 'jun_vbc_3g':'vbc_3g_6',\n",
    "                         'sep_vbc_3g':'vbc_3g_9'}, inplace=True)\n",
    "mod_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Taking only the data of high valued customer by taking average of total recharge amount of good months__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data['av_rech_amt_6_7']=((mod_data.av_rech_amt_data_6 * mod_data.total_rech_data_6 + mod_data.total_rech_amt_6)+\n",
    "                             (mod_data.av_rech_amt_data_7 * mod_data.total_rech_data_7 + mod_data.total_rech_amt_7)) / 2\n",
    "\n",
    "# mod_data.drop(['av_rech_amt_data_6','total_rech_data_6','total_rech_amt_6','av_rech_amt_data_7',\n",
    "#                'total_rech_data_7','total_rech_amt_7'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "high_value_cust = mod_data[mod_data.av_rech_amt_6_7>mod_data.av_rech_amt_6_7.quantile(0.7)]\n",
    "len(high_value_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_cust.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tagging the churned customers (churn=1, else 0) based on the fourth month as follows: Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes you need to use to tag churners are:**\n",
    "<br>\n",
    "    1. total_ic_mou_9\n",
    "    2. total_og_mou_9\n",
    "    3. vol_2g_mb_9\n",
    "    4. vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_cust['churn'] = (high_value_cust.total_ic_mou_9+high_value_cust.total_og_mou_9 + high_value_cust.vol_3g_mb_9 + high_value_cust.vol_2g_mb_9).apply(lambda x: 1 if x==0 else 0)\n",
    "high_value_cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_cust.churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('churn rate:', round((2433/27520)*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has high class imbalance, we will take care of it while building a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all the attributes corresponding to the churn phase (all attributes having ‘ _9’, etc. in their names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "high_value_cust.drop(list(filter(lambda x: x[-1]=='9',high_value_cust.columns)), axis=1, inplace=True)\n",
    "high_value_cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "high_value_cust.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As checked in the data dictionary, columns start with fb and night are schemes which are used for facebook and night packs respectively, so they are categorical columns(yes/no). Same as with churn columns. We will convert then to object type. This will help in doing EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(filter(lambda x: x.startswith('fb') or x.startswith('night'), high_value_cust.columns))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.append('churn')\n",
    "high_value_cust[cols]=high_value_cust[cols].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to add or subtract 2 columns to form a new column based on a pattern provided.\n",
    "    # col_a_end_str - pattern to search from end of column A\n",
    "    # col_b_end_str - pattern to search from end of column B\n",
    "    # avg_or_diff - 'avg' for average and 'diff' for subtraction of 2 columns\n",
    "    # new_name_end_str - end pattern to give to new columns\n",
    "    # dataframe - a dataframe   \n",
    "\n",
    "def addOrSubColumns(col_a_end_str, col_b_end_str, avg_or_diff, new_name_end_str, dataframe):\n",
    "    li=[]\n",
    "\n",
    "    s=set(filter( lambda x: x[-len(col_a_end_str):]==col_a_end_str, dataframe.select_dtypes(exclude='object').columns))\n",
    "    s1=set(filter( lambda x:  x[-len(col_b_end_str):]==col_b_end_str, dataframe.select_dtypes(exclude='object').columns))\n",
    "\n",
    "    for i in list(s):\n",
    "        k=i[:-len(col_a_end_str)]\n",
    "        a=k+col_a_end_str\n",
    "        b=k+col_b_end_str\n",
    "        if  b in s1:\n",
    "            if avg_or_diff=='diff':\n",
    "                dataframe[k+new_name_end_str]= (dataframe[b] - dataframe[a])\n",
    "            else:\n",
    "                dataframe[k+new_name_end_str]= (dataframe[b] + dataframe[a])/2\n",
    "            li+=[a,b]\n",
    "            s.remove(a); s1.remove(b)\n",
    "        \n",
    "    return dataframe.drop(li, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to capp outliers\n",
    "def cappingOutliers(dataframe, lower_quantile, upper_quantile, columns, cap=False):\n",
    "    for i in columns:\n",
    "        print('outliers in',i, ':', len(dataframe[i][(dataframe[i]>dataframe[i].quantile(upper_quantile)) | \n",
    "              (dataframe[i]<dataframe[i].quantile(lower_quantile))]))\n",
    "        if cap:\n",
    "            dataframe[i][dataframe[i]>dataframe[i].quantile(upper_quantile)] = dataframe[i].quantile(upper_quantile)\n",
    "            dataframe[i][dataframe[i]<dataframe[i].quantile(lower_quantile)] = dataframe[i].quantile(lower_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate(dataset,col,plt_type):\n",
    "    #col = dataset.columns\n",
    "    if plt_type=='single':\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        if dataset[col].dtypes != 'object':\n",
    "            sns.distplot(dataset[col])\n",
    "            dataset[col].describe()\n",
    "        else:\n",
    "            sns.countplot(dataset[col])\n",
    "            dataset[col].value_counts()\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title( 'Frequency Plot of ' + str(col) , fontsize=12, fontweight=0, color='Blue')\n",
    "    else:\n",
    "        #plt.figure(figsize=(10, 5))\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "        col1, col2, col3 =col+'_6',col+'_7',col+'_8'\n",
    "        if dataset[col1].dtypes != 'object':\n",
    "            sns.distplot(dataset[col1], ax = ax1)\n",
    "            sns.distplot(dataset[col2], ax = ax2)\n",
    "            sns.distplot(dataset[col3], ax = ax3)\n",
    "        else:\n",
    "            sns.countplot(dataset[col1], ax = ax1)\n",
    "            sns.countplot(dataset[col2], ax = ax2)\n",
    "            sns.countplot(dataset[col3], ax = ax3)\n",
    "        plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "        fig.set_size_inches(13,5)\n",
    "        fig.suptitle('Frequency Plot of ' + str(col), color = 'Blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Bivariate Analysis ---- #\n",
    "def bivariate(dataset, col1, col2):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    if (dataset[col1].dtypes == 'object' and dataset[col2].dtypes != 'object'):\n",
    "        sns.boxplot(x = col1, y = col2, data = dataset)\n",
    "        plt.xlabel(col1)\n",
    "        plt.ylabel(col2)\n",
    "    elif (dataset[col1].dtypes != 'object' and dataset[col2].dtypes == 'object'):\n",
    "        sns.boxplot(x = col2, y = col1, data = dataset)\n",
    "        if max(dataset[col1])>10000:\n",
    "            plt.yscale('log')\n",
    "        plt.xlabel(col2)\n",
    "        plt.ylabel(col1)\n",
    "    plt.title( 'Box Plot of ' + str(col1)+ ' vs '+ str(col2) , fontsize=12, fontweight=0, color='Blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot to show how a column vary in the month of June, July and August month against churn status.\n",
    "def plot_vs_Churn(dataset,col):\n",
    "    # per month churn vs Non-Churn\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "     \n",
    "    colList=list(data.filter(regex=(col)).columns)\n",
    "    colList = colList[:3]\n",
    "    plt.plot(high_value_cust.groupby('churn')[colList].mean().T)\n",
    "    ax.set_xticklabels(['Jun','Jul','Aug'])\n",
    "    \n",
    "    ## Add legend\n",
    "    plt.legend(['Non-Churn', 'Churn'])\n",
    "    \n",
    "    # Add titles\n",
    "    plt.title( str(col) +\" V/S Month\", fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()\n",
    "    \n",
    "    # Numeric stats for per month churn vs Non-Churn\n",
    "    return high_value_cust.groupby('churn')[colList].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'total_ic_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Total incoming calls drops at a faster pace for the churners from the month of June to July.\n",
    "2. For non-churners the graph is almost constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'total_og_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Total outgoing calls drops significantly for the churners from the month of June to July. We could also see that churners were quite higher in number than non churners in making outgoing calls in the month of June.\n",
    "2. For non-churners the graph is remains constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'total_rech_amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Total recharge amount drops significantly for the churners from the month of June to July. We have also observed that churners were quite spending higher amount in recharging than non churners in the month of June.\n",
    "2. For non-churners the graph is almost constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'max_rech_amt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Maximum recharge amount drops for the churners from the month of June to July and it dropped at a steep rate to August.\n",
    "2. For non-churners the graph is almost constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'arpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Average Revenue Per User drops at a faster pace for the churners from the month of June to July.The ARPU from the churners was quite higher than the non-churners in the month of June.\n",
    "2. While for non-churners the graph is almost constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'vol_2g_mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Usage volume of 2G data drops at a faster pace for the churners from the month of June to July.\n",
    "2. While for non-churners the graph is significantly same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_Churn(high_value_cust,'vol_3g_mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Usage volume of 3G data drops significantly for the churners from the month of June to July.\n",
    "2. While for non-churners the graph is fairly same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_vs_Churn(high_value_cust,'night_pck_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__\n",
    "1. Night pack users drops significantly for the churners from the month of June to July.\n",
    "2. For non-churners the graph is fairly constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After analysis we do not need these columns as we have got a derived column av_rech_amt_6_7\n",
    "high_value_cust.drop(['av_rech_amt_data_6','total_rech_data_6','total_rech_amt_6','av_rech_amt_data_7',\n",
    "               'total_rech_data_7','total_rech_amt_7'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(high_value_cust,'aon','single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "The frequency of customers is highest for lower age on network while it gradually decreases then interestingly we could see a spike in frequency at 3200 around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(high_value_cust,'av_rech_amt_6_7','single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "Most of the customers make smaller amount of recharges in the good phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(high_value_cust,'churn','single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "We could clearly see the class imbalance here as the number of churns are far less than non churners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(high_value_cust,'fb_user','multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "We could see from above frequency plots that from june to august the number of people purchasing fb_packs decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(high_value_cust,'night_pck_user','multi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "From the above frequency plots it can be seen that from june to august the number of people purchasing night_packs is fairly constant.Hence, this variable is not much significant for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the night_pack columns anf fb_user columns\n",
    "l=list(high_value_cust.select_dtypes(include='object').columns)\n",
    "l.remove('churn')\n",
    "high_value_cust.drop(l, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(high_value_cust,'aon','churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "From the above box plot it has been observed that age on network of non churners is more as compared to the churners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(high_value_cust,'av_rech_amt_6_7','churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__<br>\n",
    "From the above box plot of average recharge amount of good phase months it can be seen that the average recharge amount is more for non churners than the churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating the columns of good months\n",
    "high_value_cust = addOrSubColumns('6', '7', 'avg', '6_7', high_value_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting average recharge amount for action month\n",
    "high_value_cust['av_rech_amt_8']=(high_value_cust.av_rech_amt_data_8 * high_value_cust.total_rech_data_8 + \n",
    "                                  high_value_cust.total_rech_amt_8)\n",
    "\n",
    "high_value_cust.drop(['av_rech_amt_data_8','total_rech_data_8','total_rech_amt_8'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding difference between aggregated columns(6_7) and the action month columns\n",
    "high_value_cust = addOrSubColumns('6_7', '8', 'diff', 'diff', high_value_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the numeric columns having more than 85% of values as a single value (highly skewed columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "li=[]\n",
    "for i in high_value_cust.select_dtypes(exclude='object').columns:\n",
    "    if max(high_value_cust[i].value_counts())/len(high_value_cust) >0.85:\n",
    "        li.append(i)\n",
    "\n",
    "high_value_cust.drop(li, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "high_value_cust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outlier Treatment__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(high_value_cust.describe(percentiles=[0.01,0.05,0.25,0.5,0.75,0.9,0.95,0.99]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call the function to check and cap the outliers\n",
    "cols=list(high_value_cust.select_dtypes(exclude='object').columns) # columns to remove ouliers\n",
    "cappingOutliers(high_value_cust, 0.01,0.99, cols, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analysis on Derived Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bivariate(high_value_cust, 'total_og_mou_diff', 'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(high_value_cust, 'total_ic_mou_diff', 'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bivariate(high_value_cust,'arpu_diff','churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bivariate(high_value_cust,'vol_3g_mb_diff','churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(high_value_cust,'max_rech_data_diff','churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(high_value_cust,'max_rech_amt_diff','churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat Map for checking correlation among variables\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.title('Heat map for correlation', pad=20)\n",
    "ax=sns.heatmap(high_value_cust.corr(), linewidth =0.3, center=0, annot=True, fmt='.2f')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# !pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_cust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting churn to numeric data type\n",
    "high_value_cust['churn'] = pd.to_numeric(high_value_cust['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test\n",
    "X = high_value_cust.drop(\"churn\", axis = 1)\n",
    "y = high_value_cust.churn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print shapes of train and test sets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scaling the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Handling the class imbalance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(confusion ):\n",
    "    print('Confusion Matrix -')\n",
    "    print(confusion)\n",
    "    print('')\n",
    "    TP = confusion[1,1] # true positive \n",
    "    TN = confusion[0,0] # true negatives\n",
    "    FP = confusion[0,1] # false positives\n",
    "    FN = confusion[1,0] # false negatives\n",
    "\n",
    "    # Let's see the sensitivity of our logistic regression model\n",
    "    print('sensitivity:',TP / float(TP+FN))\n",
    "    print('')\n",
    "    \n",
    "    # Let us calculate specificity\n",
    "    print('specificity:',TN / float(TN+FP))\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = roc_curve( actual, probs, drop_intermediate = False )\n",
    "    auc_score =roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - PCA with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PCA object\n",
    "pca = PCA()\n",
    "\n",
    "# fit to train data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# look at explainded variance of PCA components\n",
    "print(pd.Series(np.round(pca.explained_variance_ratio_.cumsum(), 4)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot cumulative variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "fig = plt.figure(figsize=[5,5])\n",
    "plt.plot(cumulative_variance)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pca_components = 30\n",
    "steps = [\n",
    "         (\"pca\", IncrementalPCA(n_components=pca_components)),\n",
    "         (\"logistic\", LogisticRegression())\n",
    "        ]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca = pipeline.named_steps['pca'].fit_transform(X_train)\n",
    "corrmat = np.corrcoef(df_train_pca.transpose())\n",
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(corrmat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# check score (mean accuracy score) on train data\n",
    "pipeline.score(X_train, y_train)\n",
    "\n",
    "# predict churn on test data\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "\n",
    "# create predicted probabilities on test data\n",
    "y_pred_prob_train = pipeline.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# create confusion matrix\n",
    "confusion = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "# get scores\n",
    "getScores(confusion)\n",
    "\n",
    "# print auc-roc score\n",
    "print(\"AUC-ROC Score on train data:\", round(roc_auc_score(y_train, y_pred_prob_train),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train, y_pred_prob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# create predicted probabilities on test data\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# create confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# get scores\n",
    "getScores(confusion)\n",
    "\n",
    "# print auc-roc score\n",
    "print(\"AUC-ROC Score on test data:\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model Optimization by taking optimal cutoff value for logistic regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_df = pd.DataFrame({'y_train':y_train, 'y_pred_prob_train':y_pred_prob_train})\n",
    "logistic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = np.arange(0.3,0.71,0.05)\n",
    "print(numbers)\n",
    "for i in numbers:\n",
    "    logistic_df['cutoff_'+str(round(i,2))]= logistic_df.y_pred_prob_train.map(lambda x: 1 if x > i else 0)\n",
    "logistic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['accuracy','sensitivity','specificity'])\n",
    "\n",
    "for i in logistic_df.iloc[:,2:].columns:\n",
    "    confusion = confusion_matrix(logistic_df['y_train'], logistic_df[i])    \n",
    "    speci = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "    sensi = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "    accuracy = (confusion[0,0]+confusion[1,1])/sum(sum(confusion))\n",
    "    cutoff_df.loc[i] =[accuracy, sensi, speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(y=['accuracy','sensitivity','specificity'], figsize=(10,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "# pca = PCA()\n",
    "\n",
    "# # logistic regression - the class weight is used to handle class imbalance - it adjusts the cost function\n",
    "# logistic = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# # create pipeline\n",
    "# steps = [(\"scaler\", StandardScaler()), \n",
    "#          (\"pca\", pca),\n",
    "#          (\"logistic\", logistic)\n",
    "#         ]\n",
    "\n",
    "# # compile pipeline\n",
    "# pca_logistic = Pipeline(steps)\n",
    "\n",
    "# # hyperparameter space\n",
    "# params = {'pca__n_components': [27, 37], 'logistic__C': [0.001, 0.1, 0.5, 1, 2, 3, 4, 5, 10], 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "# # create gridsearch object\n",
    "# model = GridSearchCV(estimator=pca_logistic, cv=5, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "# pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print best hyperparameters\n",
    "# print(\"Best AUC: \", model.best_score_)\n",
    "# print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict churn on test data\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # create onfusion matrix\n",
    "# confusion = confusion_matrix(y_test, y_pred)\n",
    "# print(confusion)\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "# # Let's see the sensitivity of our logistic regression model\n",
    "# print('sensitivity:',TP / float(TP+FN))\n",
    "\n",
    "# # Let us calculate specificity\n",
    "# print('specificity:',TN / float(TN+FP))\n",
    "\n",
    "# # check area under curve\n",
    "# y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "# print(\"AUC-ROC Score on test data:\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict churn on test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "getScores(confusion)\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC-ROC Score on test data:\", round(roc_auc_score(y_test, y_pred_prob),2))\n",
    "\n",
    "draw_roc(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, scoring='roc_auc', cv = 3, n_jobs = -1,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC-ROC Score on train data: \", grid_search.best_score_)\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned=RandomForestClassifier(max_depth= 10, max_features= 10, min_samples_leaf= 100, \n",
    "                           min_samples_split= 200, n_estimators= 200)\n",
    "rf_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "# predict churn on test data\n",
    "y_pred = rf_tuned.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#get scores\n",
    "getScores(confusion)\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = rf_tuned.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC-Roc Score on test data:\", round(roc_auc_score(y_test, y_pred_prob),2))\n",
    "\n",
    "draw_roc(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model4 - XGBoost\n",
    "\n",
    "Let's finally try XGBoost. The hyperparameters are the same, some important ones being ```subsample```, ```learning_rate```, ```max_depth``` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on training data with default hyperparameters\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "# use predict_proba since we need probabilities to compute auc\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "# create onfusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#get scores\n",
    "getScores(confusion)\n",
    "\n",
    "# check area under curve\n",
    "print(\"AUC-Roc Score on test data:\", round(roc_auc_score(y_test, y_pred_prob),2))\n",
    "\n",
    "draw_roc(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hyperparameter tuning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = 3, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert parameters to int for plotting on x-axis\n",
    "cv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\n",
    "# cv_results['param_max_depth'] = cv_results['param_max_depth'].astype('float')\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]} \n",
    "\n",
    "\n",
    "for n, subsample in enumerate(param_grid['subsample']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
    "    df = cv_results[cv_results['param_subsample']==subsample]\n",
    "\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
    "    plt.xlabel('learning_rate')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"subsample={0}\".format(subsample))\n",
    "    plt.ylim([0.60, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that a subsample size of 0.6 and learning_rate of about 0.2 seems optimal. \n",
    "Also, XGBoost has resulted in the highest ROC AUC obtained (across various hyperparameters). \n",
    "\n",
    "\n",
    "Let's build a final model with the chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen hyperparameters\n",
    "# 'objective':'binary:logistic' outputs probability rather than label, which we need for auc\n",
    "params = {'learning_rate': 0.2,\n",
    "          'max_depth': 2, \n",
    "          'n_estimators':200,\n",
    "          'subsample':0.9,\n",
    "         'objective':'binary:logistic'}\n",
    "\n",
    "# fit model on training data\n",
    "model = XGBClassifier(params = params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "#The first column in y_pred is the P(0), i.e. P(not fraud), and the second column is P(1/fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "# create onfusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#get scores\n",
    "getScores(confusion)\n",
    "\n",
    "# check area under curve\n",
    "print(\"AUC-Roc Score on test data:\", round(roc_auc_score(y_test, y_pred_prob),2))\n",
    "\n",
    "draw_roc(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "importance = dict(zip(high_value_cust.columns, model.feature_importances_))\n",
    "importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
